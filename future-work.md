# Future work
The following is a list of non-negligible features that could improve the benchmark:
* In a production system where the queries implemented by the benchmark is needed often, query-results are likely to be pre-computed and saved. The benchmark could model this by creating continuous queries and rewriting the existing queries to only access the pre-computed data. This would enable using the benchmark to investigate the impact of continuous queries on the ingest- and query-performance of the target database and whether the increased storage-requirement is worth it.
* As is, the benchmark inserts data into the target database and never deletes it. While time-series systems rarely need to delete individual rows, some systems define retention policies to save storage space or reduce the impact that a large data backlog in the system has on queries on new data. The benchmark could define retention policies to delete or downsample old data which could keep e.g. partition-numbers down during a long mixed ingestion/querying benchmark-run.
* Access point metadata (e.g. their location) is only stored in the benchmark and not written to the database. Writing this data to a dedicated table in the database could potentially facilitate more flexible query implementations. This would also simplify multi-host benchmark configurations since all shared data would be accessible in the database.
* We could increase the data cardinality of the data generated by the benchmark, since data-cardinality is known to have a big effect on query performance for some database systems. Potential issues with increasing the data-cardinality (outside of getting seed data from a system to use) is how to represent this for our wide schema.
* The minimal query-language of Apache Kudu has forced the benchmark to re-implement some SQL-functionality in-application rather than performing the work on the server-side. If the benchmark adds support for Apache Impala, this can serve as an SQL-frontend for Kudu removing its query-language limitations while providing intra-query parallelism on the server-side for Kudu queries.
* The queries implemented by the benchmark do not perform any update or delete operations, and the performance of the supported database systems under a workload that includes these operations is therefore unknown. Does performance degrade over time as the database data-structures are filled with tombstones or as delta-stores grow, or does this not impact database performance at all?
* The benchmark is able to specify the partitioning-strategy for use with Kudu, providing a choice between range-, hash-, or range&hash-partitioning. No such functionality is implemented for InfluxDB or TimescaleDB which is therefore limited to their default range-partitioning setup. Additionally, supporting a variable partitioning-duration would further improve this functionality. Kudu can currently be configured with a 7- or 30-day interval but other databases are limited to their default duration.

# Extending the benchmark
## Adding support for additional databases
We have no plans to add support for additional databases, but if you wish to use this benchmark to investigate the performance of an unsupported database, then a minimal number of code-changes should be needed.

To add a new database:
1. Write an implementation of the `IQueries.java` interface for your database to support querying.
1. Write an implementation of the `ITarget.java` interface to support data-insertion.
3. Add the database to the enum in `DBTargets.java`.
4. Add your new classes to `DatabaseTargetFactory.java` and `DatabaseQueriesFactory.java`.
5. (Optional) Add config options for your database implementation in `ConfigFile.java`

## Adding additional queries
The benchmark code is not structured to allow easy addition of new queries. The following is an educated guess at what needs to be changed when adding a new query:
1. Add the new query method signature to the `IQueries.java` interface.
2. Implement the query for all existing databases and schemas.
3. Add the query to the `QueryType` enum in the `QueryRunnable.java` file. 
4. Extend the `QueryRunnable.java` file with code to handle query-argument setup, query-weights, and query-statistics for your new query.
5. (Optional) If CSV-logging support is desired, extend the `QuerySummaryLogger` class in the `CSVLogger.java` file with your new query.
6. (Optional) Add config options for your query in `ConfigFile.java`